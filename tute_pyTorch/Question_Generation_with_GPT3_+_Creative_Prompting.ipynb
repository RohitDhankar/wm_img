{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question Generation with GPT3 + Creative Prompting.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKyaGpSrl2rd"
      },
      "source": [
        "# Question Generation with GPT3 + Creative Prompting\n",
        "By: @prithivida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XZGTMchvJJ1"
      },
      "source": [
        "## Install OpenAI Python SDK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A95wLpYUneF",
        "outputId": "8502ab79-f52d-4f8a-a6ec-a391adf0d3fc"
      },
      "source": [
        "!pip install openai"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.62.3)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.4)\n",
            "Requirement already satisfied: pandas-stubs>=1.1.0.11 in /usr/local/lib/python3.7/dist-packages (from openai) (1.2.0.35)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2018.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pandas-stubs>=1.1.0.11->openai) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSYJpXJvYW9G"
      },
      "source": [
        "## Few-shot prompting with question templates\n",
        "-----\n",
        "⚡ **The Idea**\n",
        "\n",
        "For each question type (see below), Create nice reusable question templates with few examples. \n",
        "\n",
        "- Fill in the blanks\n",
        "- MCQs\n",
        "- True or False / Boolean\n",
        "- Multi-choice/Multiple Fill in the blanks\n",
        "\n",
        "Question templates are a combination of prompt tokens and question phrases. For the question generation task \"Few\" in the phrase \"few examples\" depends on the question type. For instance you will witness for Fill in the lanks and MCQs 2 examples works just fine. For True or False you could just go with 1 example and May be in your experiments you may discover Zero-short can be put to best use for your needs.\n",
        "\n",
        "**Note:**\n",
        "- Here examples simply mean string templates of some static knowledge put together to match the desired Question (and answer) style.\n",
        "- Having categories of templates can help, because the closer your templates are with the actual paragraphs you are using to generate question in terms of domains the stronger will be the generation results.\n",
        "\n",
        "**Disclaimer:**\n",
        "- The strength and quality of your generations are a function of your Prompt Tokens and Example phrases. Choose creative yet relevant prompt tokens.\n",
        "- PROMPT PROGRAMMING is a SKILL you can improve purely by TRIAL AND ERROR with your ENGLISH knowledge. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qR9Wdv1cG_h"
      },
      "source": [
        "#### 1. Fill in the blanks\n",
        "------\n",
        "\n",
        "**Below is a sample prompt template for Fill in the blank questions** As said before the examples are based on the some static knowledge. Here we have 2 ``` <Paragraph/Ques-Ans> ``` pairs. You can have as many example as you want. In this example ```Paragraph:, Question:, Answer: ``` are the 3 prompt tokens. \n",
        "\n",
        "* Line 1. Paragraph: Jesus, according to some biblical sources, was born in this town some two millennia ago in Bethlehem. \n",
        "* Line 2. Question: Where was Jesus born ______ ? Answer: Bethlehem \n",
        "* Line 3. Paragraph: Sachin Tendulkar was born in India. He debuted for Indian cricket in 1988. \n",
        "* Line 4. Question: In ______ Sachin started playing cricket? Answer: 1988"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeKxlflpgCBs"
      },
      "source": [
        "import openai\n",
        "openai.api_key = \"<paste your api key here>\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiTjmQzVTfm1",
        "outputId": "44cf6830-bd0c-4c6c-b0e3-3873f5748a06"
      },
      "source": [
        "prompt_template= \"\"\"\n",
        "Paragraph: Jesus, according to some biblical sources, was born in this town some two millennia ago in Bethlehem. \n",
        "Question: Where was Jesus born ______ ? Answer: Bethlehem\n",
        "Paragraph: Sachin Tendulkar was born in India. He debuted for Indian cricket in 1988. \n",
        "Question: In ______ Sachin started playing cricket. Answer: 1988\n",
        "\"\"\"\n",
        "\n",
        "custom_prompt=\"\"\"\n",
        "Paragraph: Elon Musk was a born in South Africa in 1971 and he joined Tesla in 2004.\n",
        "\"\"\"\n",
        "\n",
        "prompt = prompt_template + custom_prompt\n",
        "completion = openai.Completion.create(engine=\"davinci\", prompt=prompt, max_tokens=32, temperature=0.7)\n",
        "\n",
        "print(\"Generated Question..\")\n",
        "generated = completion.choices[0].text\n",
        "if \"Paragraph\" in generated:\n",
        "   ind = generated.index(\"Paragraph\") \n",
        "   print(generated[:ind])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated\n",
            "Question: When did Elon Musk founded Tesla Motors ______ ? Answer: 2004\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8at1fVvdXVh"
      },
      "source": [
        "#### 2. MCQ - Multiple Choice Questions\n",
        "------\n",
        "\n",
        "**Below is a sample prompt template for MCQs** As said before the examples are based on the some static knowledge. Here we have 2 ``` <Paragraph/Ques-Choice-Ans> ``` pairs. You can have as many as you want to make the generation strong.\n",
        "\n",
        "* Line 1. Paragraph: Jesus, according to some biblical sources, was born in this town some two millennia ago in Bethlehem. The story begins with wise men who come to the city of Jerusalem after seeing a star that they interpreted as signaling the birth of a new king.\n",
        "* Line 2. Question: Where was Jesus born ? A) Jerusalem, B) Palestine, C) Bethlehem. D) Tel-Aviv Answer: C\n",
        "* Line 3. Paragraph: Sachin Tendulkar was born in India 1972. He debuted for Indian cricket in 1988 and retired in 2011.\n",
        "* Line 4. Question: In what year Sachin started playing cricket? A) 1972, B) 1988, C) 2011, D) 2001. Answer: B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2Z533gJU1lP",
        "outputId": "ec3a6d76-c8be-4ede-a0de-9dd052549f8a"
      },
      "source": [
        "prompt_template= \"\"\"\n",
        "Paragraph: Jesus, according to some biblical sources, was born in this town some two millennia ago in Bethlehem. The story begins with wise men who come to the city of Jerusalem after seeing a star that they interpreted as signaling the birth of a new king.\n",
        "Question: Where was Jesus born ? A) Jerusalem, B) Palestine, C) Bethlehem. D) Tel-Aviv Answer: C\n",
        "Paragraph: Sachin Tendulkar was born in India 1972. He debuted for Indian cricket in 1988 and retired in 2011.\n",
        "Question: In what year Sachin started playing cricket? A) 1972, B) 1988, C) 2011, D) 2001. Answer: B\n",
        "\"\"\"\n",
        "\n",
        "custom_prompt=\"\"\"\n",
        "Paragraph: Elon Musk was a born in South Africa in 1971 and he joined Tesla in 2004.\n",
        "\"\"\"\n",
        "\n",
        "prompt = prompt_template + custom_prompt\n",
        "completion = openai.Completion.create(engine=\"davinci\", prompt=prompt, max_tokens=32, temperature=0.7)\n",
        "\n",
        "print(\"Generated Question..\")\n",
        "generated = completion.choices[0].text\n",
        "if \"Paragraph\" in generated:\n",
        "   ind = generated.index(\"Paragraph\") \n",
        "   print(generated[:ind])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Question..\n",
            "Question: When did Elon join Tesla? A) 1971, B) 2004, C) 2010, D) 2014. Answer: B\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uso4VLJgG-X"
      },
      "source": [
        "#### 3. True or False / Boolean Questions\n",
        "------\n",
        "Here we have ONLY 1 ``` <Paragraph/Ques-Ans> ``` pair.  But be warned generation might suffer. More the examples in your template Stronger the generations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OQnU3IVexWK",
        "outputId": "c83dfe0f-5198-4589-c94e-862cc9c775ba"
      },
      "source": [
        "prompt_template= \"\"\"\n",
        "Paragraph: Jesus, according to some biblical sources, was born in this town some two millennia ago in Bethlehem. The story begins with wise men who come to the city of Jerusalem after seeing a star that they interpreted as signaling the birth of a new king.\n",
        "Question: Jesus was born in Jerusalem. Answer: False\n",
        "\"\"\"\n",
        "\n",
        "custom_prompt=\"\"\"\n",
        "Paragraph: Elon Musk was a born in South Africa in 1971 and he joined Tesla in 2004.\n",
        "\"\"\"\n",
        "\n",
        "prompt = prompt_template + custom_prompt\n",
        "completion = openai.Completion.create(engine=\"davinci\", prompt=prompt, max_tokens=32, temperature=0.7)\n",
        "\n",
        "print(\"Generated Question..\")\n",
        "generated = completion.choices[0].text\n",
        "if \"Paragraph\" in generated:\n",
        "   ind = generated.index(\"Paragraph\") \n",
        "   print(generated[:ind])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Question..\n",
            "Question: Elon Musk was a born in South Africa. Answer: True\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y-cAhmsmlL5"
      },
      "source": [
        "#### 4. (Just for fun) Lets try generating higher-order probing questions which either needs common sense or deeper inference.\n",
        "------\n",
        "Note how we changed the prompt strings to ```<fact/probe-inference>``` pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv2DgR0xm3zR",
        "outputId": "98cc11f9-4bbe-42f5-9826-d68c8f4ef662"
      },
      "source": [
        "prompt_template= \"\"\"\n",
        "Fact: Jesus, according to some biblical sources, was born in this town some two millennia ago in Bethlehem. The story begins with wise men who come to the city of Jerusalem after seeing a star that they interpreted as signaling the birth of a new king.\n",
        "Probe: Is Jesus a human being? Inference: No he is a God.\n",
        "Fact: Sachin Tendulkar was born in India 1972. He debuted for Indian cricket in 1988 and retired in 2011.\n",
        "Probe: How many years Sachin played cricket? Inference: 23 years.\n",
        "\"\"\"\n",
        "\n",
        "custom_prompt=\"\"\"\n",
        "Fact: Elon Musk started Tesla Motors since 2004. He is the CEO and product architect of Tesla and he is also the Chairman of Musk Foundation, an organization supporting research on renewable energy, human space exploration and pediatrics. At age 12, sold his code for a video game called “Blastar” to a computer magazine for $500.\n",
        "\"\"\"\n",
        "\n",
        "prompt = prompt_template + custom_prompt\n",
        "completion = openai.Completion.create(engine=\"davinci\", prompt=prompt, max_tokens=32, temperature=0.7)\n",
        "\n",
        "print(\"Generated Probe..\")\n",
        "generated = completion.choices[0].text\n",
        "if \"Fact\" in generated:\n",
        "   ind = generated.index(\"Fact\") \n",
        "   print(generated[:ind])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Probe..\n",
            "Probe: How much money he earned at 12? Inference: 500$.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynx2qOSDgJVO"
      },
      "source": [
        "### Important Note\n",
        "\n",
        "- Signup for OpenAI to get your own API key !\n",
        "- Engine choice: Davinci is not the only engine of choice \n",
        "```\n",
        "# list engines\n",
        "engines = openai.Engine.list()\n",
        "```\n",
        "Play with the list using the above snippet and choose the one that best suits your case.\n",
        "- Number of generations - As you can see, I have limited my generations to only 1. You could iterate over many generations with single prompt\n",
        "- Play with misc Parameters like ```max_tokens=32, temperature=0.7``` Refer this link  -https://beta.openai.com/docs/api-reference/completions/create\n",
        "- Feel free to use your creativity and rxpand to other tasks"
      ]
    }
  ]
}